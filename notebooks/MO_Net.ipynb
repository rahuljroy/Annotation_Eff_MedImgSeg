{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agccua2e4WBj"
   },
   "outputs": [],
   "source": [
    "# ! cp drive/My\\ Drive/CT.zip .\n",
    "# ! unzip CT.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2z3NO4MF3-n2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ngpu = torch.cuda.device_count()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, ngpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeM7FFkX4a_h"
   },
   "outputs": [],
   "source": [
    "img_name = '62_50.bmp'\n",
    "mask_name = img_name\n",
    "\n",
    "im = Image.open(os.path.join('CT/test/img/', img_name))\n",
    "# im = ImageOps.grayscale(im)\n",
    "im = im.resize((256, 256))\n",
    "im = np.array(im)\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "seg = Image.open(os.path.join('CT/test/seg_w', mask_name))\n",
    "seg = seg.resize((256, 256))\n",
    "seg = np.array(seg)\n",
    "plt.imshow(seg, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ku76FG0U4cHe"
   },
   "outputs": [],
   "source": [
    "def load_batch(batch_size = 20, dims=(256, 256), data_path='CT/train/'):\n",
    "    img_names = np.array(os.listdir(data_path+'img'))\n",
    "    mask_names = np.array([x for x in img_names])\n",
    "    shuffled_idxs = np.random.permutation(len(img_names))\n",
    "    shuffled_img_names = img_names[shuffled_idxs]\n",
    "    shuffled_mask_names = mask_names[shuffled_idxs]\n",
    "    no_of_batches = img_names.shape[0] // batch_size\n",
    "    extra_batch = img_names.shape[0] % batch_size\n",
    "    for i in range(no_of_batches):\n",
    "        # print(shuffled_img_names[i*batch_size:(i+1)*batch_size].shape)\n",
    "        imgs, segs, p_segs = [], []\n",
    "        for j in range(batch_size):\n",
    "            im = Image.open(os.path.join(data_path+'img', shuffled_img_names[i*batch_size+j]))\n",
    "            seg = Image.open(os.path.join(data_path+'seg_w', shuffled_mask_names[i*batch_size+j]))\n",
    "            seg_p = Image.open(os.path.join(data_path+'seg_l', shuffled_mask_names[i*batch_size+j]))\n",
    "            im = ImageOps.grayscale(im)\n",
    "            im = im.resize(dims)\n",
    "            seg = seg.resize(dims)\n",
    "            seg_p = seg_p.resize(dims)\n",
    "            im = np.array(im) / 255.\n",
    "            seg = np.array(seg) / 255.\n",
    "            seg_p = np.array(seg_p) / 255.\n",
    "            imgs.append(im)\n",
    "            segs.append(seg)\n",
    "            p_segs.append(seg_p)\n",
    "        yield (torch.FloatTensor(imgs).view(batch_size,1,dims[0],dims[1]).to(device),\n",
    "               torch.FloatTensor(segs).view(batch_size,1,dims[0],dims[1]).to(device),\n",
    "               torch.FloatTensor(p_segs).view(batch_size,1,dims[0],dims[1]).to(device))\n",
    "    if extra_batch:\n",
    "        imgs, segs = [], []\n",
    "        for j in range(extra_batch):\n",
    "            im = Image.open(os.path.join(data_path+'img', shuffled_img_names[(i+1)*batch_size]))\n",
    "            seg = Image.open(os.path.join(data_path+'seg_w', shuffled_mask_names[(i+1)*batch_size]))\n",
    "            seg_p = Image.open(os.path.join(data_path+'seg_l', shuffled_mask_names[(i+1)*batch_size]))\n",
    "            im = ImageOps.grayscale(im)\n",
    "            im = im.resize(dims)\n",
    "            seg = seg.resize(dims)\n",
    "            seg_p = seg_p.resize(dims)\n",
    "            im = np.array(im) / 255.\n",
    "            seg = np.array(seg) / 255.\n",
    "            seg_p = np.array(seg_p) / 255.\n",
    "            imgs.append(im)\n",
    "            segs.append(seg)\n",
    "            p_segs.append(seg_p)\n",
    "        yield (torch.FloatTensor(imgs).view(extra_batch,1,dims[0],dims[1]).to(device),\n",
    "               torch.FloatTensor(segs).view(extra_batch,1,dims[0],dims[1]).to(device),\n",
    "               torch.FloatTensor(p_segs).view(extra_batch,1,dims[0],dims[1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqM8-tKW4e4Q"
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, num_channels, num_filters):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, num_filters, (3, 3), padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(num_filters)\n",
    "        self.conv2 = nn.Conv2d(num_filters, num_filters, (3, 3), padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(num_filters) sasha sloan\n",
    "    \n",
    "    def forward(self, inp_tensor):\n",
    "        encoder = self.conv1(inp_tensor)\n",
    "        encoder = self.conv1_bn(encoder)\n",
    "        encoder = torch.relu(encoder)\n",
    "        encoder = self.conv2(encoder)\n",
    "        encoder = self.conv2_bn(encoder)\n",
    "        encoder = torch.relu(encoder)\n",
    "        return encoder\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, num_channels, num_filters):\n",
    "        super(encoder_block, self).__init__()\n",
    "        self.conv_block1 = conv_block(num_channels, num_filters)\n",
    "        self.max_pool1 = nn.MaxPool2d((2, 2), (2, 2))\n",
    "    \n",
    "    def forward(self, inp_tensor):\n",
    "        encoder = self.conv_block1(inp_tensor)\n",
    "        encoder_pool = self.max_pool1(encoder)\n",
    "        return (encoder_pool, encoder)\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, num_channels, num_filters):\n",
    "        super(decoder_block, self).__init__()\n",
    "        self.conv_tp1 = nn.ConvTranspose2d(num_channels, num_filters, (2, 2), stride=(2, 2))\n",
    "        self.conv_tp1_bn = nn.BatchNorm2d(2*num_filters)\n",
    "        self.conv_tp2 = nn.Conv2d(2*num_filters, num_filters, (3, 3), padding=1)\n",
    "        self.conv_tp2_bn = nn.BatchNorm2d(num_filters)\n",
    "        self.conv_tp3 = nn.Conv2d(num_filters, num_filters, (3, 3), padding=1)\n",
    "        self.conv_tp3_bn = nn.BatchNorm2d(num_filters)\n",
    "\n",
    "    def forward(self, inp_tensor, concat_tensor):\n",
    "        decoder = self.conv_tp1(inp_tensor)\n",
    "        decoder = torch.cat((concat_tensor, decoder), 1)\n",
    "        decoder = self.conv_tp1_bn(decoder)\n",
    "        decoder = torch.relu(decoder)\n",
    "        decoder = self.conv_tp2(decoder)\n",
    "        decoder = self.conv_tp2_bn(decoder)\n",
    "        decoder = torch.relu(decoder)\n",
    "        decoder = self.conv_tp3(decoder)\n",
    "        decoder = self.conv_tp3_bn(decoder)\n",
    "        decoder = torch.relu(decoder)\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNh6d0p35ZU_"
   },
   "outputs": [],
   "source": [
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(UNet2D, self).__init__()\n",
    "        self.encoder_block0 = encoder_block(num_channels, 32)\n",
    "        self.encoder_block1 = encoder_block(32, 64)\n",
    "        self.encoder_block2 = encoder_block(64, 128)\n",
    "        self.encoder_block3 = encoder_block(128, 256)\n",
    "        self.encoder_block4 = encoder_block(256, 512)\n",
    "        self.center = conv_block(512, 1024)\n",
    "        self.decoder_block4 = decoder_block(1024, 512)\n",
    "        self.decoder_block3 = decoder_block(512, 256)\n",
    "        self.decoder_block2 = decoder_block(256, 128)\n",
    "        self.decoder_block1 = decoder_block(128, 64)\n",
    "        self.decoder_block0 = decoder_block(64, 32)\n",
    "        self.conv_final = nn.Conv2d(32, 1, (1, 1))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # inputs = x # 256\n",
    "\n",
    "        encoder0_pool, encoder0 = self.encoder_block0(inputs) # 128\n",
    "        encoder1_pool, encoder1 = self.encoder_block1(encoder0_pool) # 64\n",
    "        encoder2_pool, encoder2 = self.encoder_block2(encoder1_pool) # 32\n",
    "        encoder3_pool, encoder3 = self.encoder_block3(encoder2_pool) # 16\n",
    "        encoder4_pool, encoder4 = self.encoder_block4(encoder3_pool) # 8\n",
    "\n",
    "        center = self.center(encoder4_pool) # center (8)\n",
    "\n",
    "        decoder4 = self.decoder_block4(center, encoder4) # 16\n",
    "        decoder3 = self.decoder_block3(decoder4, encoder3) # 32\n",
    "        decoder2 = self.decoder_block2(decoder3, encoder2) # 64\n",
    "        decoder1 = self.decoder_block1(decoder2, encoder1) # 128\n",
    "        decoder0 = self.decoder_block0(decoder1, encoder0) # 256\n",
    "\n",
    "        outputs = torch.sigmoid(self.conv_final(decoder0))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--oraE5r5dqN"
   },
   "outputs": [],
   "source": [
    "class MO_Net_encoder(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MO_Net_encoder, self).__init__()\n",
    "        self.encoder_block0 = encoder_block(num_channels, 32)\n",
    "        self.encoder_block1 = encoder_block(32, 64)\n",
    "        self.encoder_block2 = encoder_block(64, 128)\n",
    "        self.encoder_block3 = encoder_block(128, 256)\n",
    "        self.encoder_block4 = encoder_block(256, 512)\n",
    "        self.center = conv_block(512, 1024)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs = x # 256\n",
    "\n",
    "        encoder0_pool, encoder0 = self.encoder_block0(inputs) # 128\n",
    "        encoder1_pool, encoder1 = self.encoder_block1(encoder0_pool) # 64\n",
    "        encoder2_pool, encoder2 = self.encoder_block2(encoder1_pool) # 32\n",
    "        encoder3_pool, encoder3 = self.encoder_block3(encoder2_pool) # 16\n",
    "        encoder4_pool, encoder4 = self.encoder_block4(encoder3_pool) # 8\n",
    "        center = self.center(encoder4_pool) # center (8)\n",
    "\n",
    "        return center\n",
    "\n",
    "\n",
    "class MO_Net_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MO_Net_decoder, self).__init__()\n",
    "        self.decoder_block4 = decoder_block(1024, 512)\n",
    "        self.decoder_block3 = decoder_block(512, 256)\n",
    "        self.decoder_block2 = decoder_block(256, 128)\n",
    "        self.decoder_block1 = decoder_block(128, 64)\n",
    "        self.decoder_block0 = decoder_block(64, 32)\n",
    "        self.conv_final = nn.Conv2d(32, 1, (1, 1))\n",
    "            \n",
    "    def forward(self, center):\n",
    "        # center = x # (8)\n",
    "\n",
    "        decoder4 = self.decoder_block4(center, encoder4) # 16\n",
    "        decoder3 = self.decoder_block3(decoder4, encoder3) # 32\n",
    "        decoder2 = self.decoder_block2(decoder3, encoder2) # 64\n",
    "        decoder1 = self.decoder_block1(decoder2, encoder1) # 128\n",
    "        decoder0 = self.decoder_block0(decoder1, encoder0) # 256\n",
    "\n",
    "        outputs = torch.sigmoid(self.conv_final(decoder0))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alXT_IDN6x6D"
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    assert y_true.shape == y_pred.shape, \"Tensor dimensions must match\"\n",
    "    shape = y_true.shape\n",
    "    y_true_flat = y_true.view(shape[0]*shape[1]*shape[2]*shape[3],)\n",
    "    y_pred_flat = y_pred.view(shape[0]*shape[1]*shape[2]*shape[3],)\n",
    "    intersection = torch.sum(y_true_flat * y_pred_flat)\n",
    "    score = (2. * intersection + smooth) / (torch.sum(y_true_flat) + torch.sum(y_pred_flat) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = F.binary_cross_entropy(y_pred, y_true) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W58epStO64Sg"
   },
   "outputs": [],
   "source": [
    "# PHASE 1\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 5\n",
    "\n",
    "losses = []\n",
    "dscoeffs = []\n",
    "avg_losses = []\n",
    "val_avg_losses = []\n",
    "avg_dscoeffs = []\n",
    "val_avg_dscoeffs = []\n",
    "\n",
    "model0 = UNet2D(1).to(device)\n",
    "optimizer = optim.Adam(model0.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdC5ooyN7DfI"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    model0.train()\n",
    "    avg_loss = 0.0\n",
    "    avg_dscoeff = 0.0\n",
    "    print('---------- EPOCH:', epoch, '----------')\n",
    "    print('----------- TRAINING -------------')\n",
    "    for i, (imgs, _, segs) in enumerate(load_batch(batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model0(imgs)\n",
    "        loss = bce_dice_loss(segs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        dscoeff = dice_coeff(segs, outputs).item()\n",
    "        print(\"Epoch:\", epoch, \"| Iter:\", i+1, \"| loss:\", round(loss.item(), 4), \"| dsc:\", round(dscoeff, 4))\n",
    "        losses.append(loss.item())\n",
    "        dscoeffs.append(dscoeff)\n",
    "        avg_loss += loss.item()\n",
    "        avg_dscoeff += dscoeff\n",
    "    print('-------------- DONE --------------')\n",
    "    model0.eval()\n",
    "    val_avg_loss = 0.0\n",
    "    val_avg_dscoeff = 0.0\n",
    "    print('---------- VALIDATING ------------')\n",
    "    for j, (imgs, _, segs) in enumerate(load_batch(batch_size, data_path='CT/test/')):\n",
    "        outputs = model0(imgs)\n",
    "        loss = bce_dice_loss(segs, outputs)\n",
    "        dscoeff = dice_coeff(segs, outputs).item()\n",
    "        print(\"Epoch:\", epoch, \"| Iter:\", j+1, \"| loss:\", round(loss.item(), 4), \"| dsc:\", round(dscoeff, 4))\n",
    "        val_avg_loss += loss.item()\n",
    "        val_avg_dscoeff += dscoeff\n",
    "    print('-------------- DONE --------------')\n",
    "    print()\n",
    "    avg_loss = round(avg_loss/(i+1), 4)\n",
    "    avg_dscoeff = round(avg_dscoeff/(i+1), 4)\n",
    "    val_avg_loss = round(val_avg_loss/(j+1), 4)\n",
    "    val_avg_dscoeff = round(val_avg_dscoeff/(j+1), 4)\n",
    "    avg_losses.append(avg_loss)\n",
    "    val_avg_losses.append(val_avg_loss)\n",
    "    avg_dscoeffs.append(avg_dscoeff)\n",
    "    val_avg_dscoeffs.append(val_avg_dscoeff)\n",
    "    print(\"Epoch:\", epoch, \"| loss:\", avg_loss, \"| dsc:\", avg_dscoeff,\n",
    "          \"| val_loss:\", val_avg_loss, \"| val_dsc:\", val_avg_dscoeff)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAUTYrFh7K3I"
   },
   "outputs": [],
   "source": [
    "# PHASE 2\n",
    "\n",
    "epochs = 6\n",
    "batch_size = 5\n",
    "Lambda = 0.7\n",
    "\n",
    "losses = []\n",
    "dscoeffs = []\n",
    "avg_losses = []\n",
    "val_avg_losses = []\n",
    "avg_dscoeffs = []\n",
    "val_avg_dscoeffs = []\n",
    "\n",
    "model_enc = MO_Net_encoder(1).to(device)\n",
    "model_dec1 = MO_Net_decoder().to(device)\n",
    "model_dec2 = MO_Net_decoder().to(device)\n",
    "params1 = model0.state_dict()\n",
    "params2 = model_enc.state_dict()\n",
    "params3 = model_dec1.state_dict()\n",
    "params4 = model_dec2.state_dict()\n",
    "for item in params1:\n",
    "    if item in params2:\n",
    "        params2[item] = params1[item]\n",
    "for item in params1:\n",
    "    if item in params3:\n",
    "        params3[item] = params1[item]\n",
    "for item in params1:\n",
    "    if item in params4:\n",
    "        params4[item] = params1[item]\n",
    "model_enc.load_state_dict(params2)\n",
    "model_dec1.load_state_dict(params3)\n",
    "model_dec2.load_state_dict(params4)\n",
    "optimizer0 = optim.Adam(model_enc.parameters(), lr = 0.000003)\n",
    "optimizer1 = optim.Adam(model_dec1.parameters(), lr = 0.000001)\n",
    "optimizer2 = optim.Adam(model_dec2.parameters(), lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-hRWb10PjyM"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    model_enc.train()\n",
    "    model_dec1.train()\n",
    "    model_dec2.train()\n",
    "    avg_loss = 0.0\n",
    "    avg_dscoeff = 0.0\n",
    "    print('---------- EPOCH:', epoch, '----------')\n",
    "    print('----------- TRAINING -------------')\n",
    "    for i, (imgs, segs, p_segs) in enumerate(load_batch(batch_size)):\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "        outputs1 = model_dec1(model_enc(imgs))\n",
    "        outputs2 = model_dec2(model_enc(imgs))\n",
    "        loss1 = bce_dice_loss(p_segs, outputs1)\n",
    "        loss2 = bce_dice_loss(segs, outputs2)\n",
    "        loss = ((1 - Lambda) * loss1) + (Lambda * loss2)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        optimizer3.step()\n",
    "        optimizer1.step()\n",
    "        dscoeff = dice_coeff(segs, outputs2).item()\n",
    "        print(\"Epoch:\", epoch, \"| Iter:\", i+1, \"| loss:\", round(loss.item(), 4), \"| dsc:\", round(dscoeff, 4))\n",
    "        losses.append(loss.item())\n",
    "        dscoeffs.append(dscoeff)\n",
    "        avg_loss += loss.item()\n",
    "        avg_dscoeff += dscoeff\n",
    "    print('-------------- DONE --------------')\n",
    "    model_enc.eval()\n",
    "    model_dec1.eval()\n",
    "    model_dec2.eval()\n",
    "    val_avg_loss = 0.0\n",
    "    val_avg_dscoeff = 0.0\n",
    "    print('---------- VALIDATING ------------')\n",
    "    for j, (imgs, segs, p_segs) in enumerate(load_batch(batch_size, data_path='CT/test/')):\n",
    "        outputs1 = model_dec1(model_enc(imgs))\n",
    "        outputs2 = model_dec2(model_enc(imgs))\n",
    "        loss1 = bce_dice_loss(p_segs, outputs1)\n",
    "        loss2 = bce_dice_loss(segs, outputs2)\n",
    "        loss = ((1 - Lambda) * loss1) + (Lambda * loss2)\n",
    "        dscoeff = dice_coeff(segs, outputs2).item()\n",
    "        print(\"Epoch:\", epoch, \"| Iter:\", j+1, \"| loss:\", round(loss.item(), 4), \"| dsc:\", round(dscoeff, 4))\n",
    "        val_avg_loss += loss.item()\n",
    "        val_avg_dscoeff += dscoeff\n",
    "    print('-------------- DONE --------------')\n",
    "    print()\n",
    "    avg_loss = round(avg_loss/(i+1), 4)\n",
    "    avg_dscoeff = round(avg_dscoeff/(i+1), 4)\n",
    "    val_avg_loss = round(val_avg_loss/(j+1), 4)\n",
    "    val_avg_dscoeff = round(val_avg_dscoeff/(j+1), 4)\n",
    "    avg_losses.append(avg_loss)\n",
    "    val_avg_losses.append(val_avg_loss)\n",
    "    avg_dscoeffs.append(avg_dscoeff)\n",
    "    val_avg_dscoeffs.append(val_avg_dscoeff)\n",
    "    print(\"Epoch:\", epoch, \"| loss:\", avg_loss, \"| dsc:\", avg_dscoeff,\n",
    "          \"| val_loss:\", val_avg_loss, \"| val_dsc:\", val_avg_dscoeff)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYzMpEANRTJD"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Loss plot')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(dscoeffs)\n",
    "plt.title('Performance plot')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('DSC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQ0e8pz4RXy6"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.title('Loss plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(avg_dscoeffs)\n",
    "plt.title('Performance plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('DSC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BVWALOsRcNW"
   },
   "outputs": [],
   "source": [
    "plt.plot(val_avg_losses)\n",
    "plt.title('Loss plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_avg_dscoeffs)\n",
    "plt.title('Performance plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('DSC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgu-N9upRiev"
   },
   "outputs": [],
   "source": [
    "img_name = '62_50.bmp'\n",
    "mask_name = img_name\n",
    "\n",
    "im = Image.open(os.path.join('CT/test/img', img_name))\n",
    "# im = ImageOps.grayscale(im)\n",
    "im = im.resize((256, 256))\n",
    "im = np.array(im) / 255.\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "seg = Image.open(os.path.join('CT/test/seg_w', mask_name))\n",
    "seg = seg.resize((256, 256))\n",
    "seg = np.array(seg)\n",
    "plt.imshow(seg, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "model_enc.eval()\n",
    "model_dec2.eval()\n",
    "out = model_dec2(model_enc(torch.FloatTensor(im.reshape((1,1,256,256))).to(device)))\n",
    "plt.imshow(out.data.cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MO-Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
